{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##*Welcome to the exercise for the course Information Systems*\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5eimI32ODa1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Data Preprocessing"
      ],
      "metadata": {
        "id": "oW205cceDv57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 Importing the Libraries"
      ],
      "metadata": {
        "id": "6zYpNHRwEeio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "LjMtv_34DjUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 Importing the Dataset"
      ],
      "metadata": {
        "id": "XFT9SsD4KnXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Employee.csv')\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "rbyVlgjqKu1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1aa6377-f556-42a4-c7d1-c249b54a9bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
            "0     Bachelors         2017  Bangalore            3   34    Male          No   \n",
            "1     Bachelors         2013       Pune            1   28  Female          No   \n",
            "2     Bachelors         2014  New Delhi            3   38  Female          No   \n",
            "3       Masters         2016  Bangalore            3   27    Male          No   \n",
            "4       Masters         2017       Pune            3   24    Male         Yes   \n",
            "...         ...          ...        ...          ...  ...     ...         ...   \n",
            "4648  Bachelors         2013  Bangalore            3   26  Female          No   \n",
            "4649    Masters         2013       Pune            2   37    Male          No   \n",
            "4650    Masters         2018  New Delhi            3   27    Male          No   \n",
            "4651  Bachelors         2012  Bangalore            3   30    Male         Yes   \n",
            "4652  Bachelors         2015  Bangalore            3   33    Male         Yes   \n",
            "\n",
            "      ExperienceInCurrentDomain  LeaveOrNot  \n",
            "0                             0           0  \n",
            "1                             3           1  \n",
            "2                             2           0  \n",
            "3                             5           1  \n",
            "4                             2           1  \n",
            "...                         ...         ...  \n",
            "4648                          4           0  \n",
            "4649                          2           1  \n",
            "4650                          5           1  \n",
            "4651                          2           0  \n",
            "4652                          4           0  \n",
            "\n",
            "[4653 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.3 Exploring the data to see what we are dealing with"
      ],
      "metadata": {
        "id": "uZDAd1P_aBbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "jW97O1uCEVKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.4 Looking for Missing Data"
      ],
      "metadata": {
        "id": "YlQ5tlmlFXTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "x30STL9NEyV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.5 Isolating the variable we want to predict (dependent variable)"
      ],
      "metadata": {
        "id": "xzYa0g0HZAoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "GZZdB5XFZGqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.6 Creating the matrix of independent variables"
      ],
      "metadata": {
        "id": "CLoj6YcUZKm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.6.1 Label encoder for Education, Gender and EverBenched"
      ],
      "metadata": {
        "id": "1KO8ngmkI5Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "dataset['Education Cat'] = label_encoder.fit_transform(dataset['Education'])\n",
        "dataset['EverBenched Cat'] = label_encoder.fit_transform(dataset['EverBenched'])\n",
        "dataset['Gender Cat'] = label_encoder.fit_transform(dataset['Gender'])\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "ppKi2wzGI4tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.6.2 OneHotEncoder for City\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xJ-4ikyTUebb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# creating instance of one hot encoder\n",
        "enc = OneHotEncoder()\n",
        "\n",
        "# one hot encoder gender and city feature\n",
        "dum_city_dataset = pd.get_dummies(dataset['City'])\n",
        "\n",
        "# concate\n",
        "dataset = pd.concat([dataset, dum_city_dataset], axis='columns')\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "V6EzAPLAUdwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.6.3 Deleting the Columns we don't need"
      ],
      "metadata": {
        "id": "lghK4e4eW6yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.drop(['Education', 'City', 'Gender', 'EverBenched', 'LeaveOrNot', 'Pune'], axis=1)\n",
        "\n",
        "X"
      ],
      "metadata": {
        "id": "_qgQ4mW6XBBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.7 Splitting the dataset into the training set and the test set"
      ],
      "metadata": {
        "id": "LBVVjqopu_MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "jbNAfBenvGG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Naive Bayes Prediction Model"
      ],
      "metadata": {
        "id": "VdOcrohFtH6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1 Training the Naive Bayes Model on the Training Set"
      ],
      "metadata": {
        "id": "IqToDRAYw1kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "AHYKKRL_w5o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2 Predicting the Test Set Results"
      ],
      "metadata": {
        "id": "KEd5byijxBo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "SqRJ3xw9xFNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.3 Making the Confusion Matrix and Calculating the Accuracy"
      ],
      "metadata": {
        "id": "8wK68E43xRry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "rlNmM3oNxV1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. K-NN Prediction Model"
      ],
      "metadata": {
        "id": "S1KnG2OPrnAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1 Standardization of certain features"
      ],
      "metadata": {
        "id": "Q6KEJlJSr_53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[['JoiningYear', 'Age', 'ExperienceInCurrentDomain']]=sc.fit_transform(X_train[['JoiningYear', 'Age', 'ExperienceInCurrentDomain']])\n",
        "\n",
        "X_test[['JoiningYear', 'Age', 'ExperienceInCurrentDomain']] = sc.fit_transform(X_test[['JoiningYear', 'Age', 'ExperienceInCurrentDomain']])"
      ],
      "metadata": {
        "id": "omaOr0F929Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "Ig5VuTF74jNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "id": "fzNdTrnG4zlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.2 Training the K-NN model on the Training set"
      ],
      "metadata": {
        "id": "w1zNQGZQ5RKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_O0WuQHg5XBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.3 Predicting the Test set results"
      ],
      "metadata": {
        "id": "EoeKCmTV5iB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "Vv2AIQNo5kuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.4 Making the Confusion Matrix and calculating accuracy"
      ],
      "metadata": {
        "id": "vgfC8x_O5qbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Q2wK_M255swr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Random Forests Prediction Model"
      ],
      "metadata": {
        "id": "DM0V6JRltW11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.1 Training the Random Forest Classification model on the Training set"
      ],
      "metadata": {
        "id": "vsvJ_YlGtxjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "CGEz7uydtrn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.2 Predicting the Test set results"
      ],
      "metadata": {
        "id": "MNUDxvIDt-_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "xwtmXjLSuDc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.3 Making the Confusion Matrix and calculating accuracy"
      ],
      "metadata": {
        "id": "9aFo3hcluCWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "BCxz9uWruL4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Logistic Regression Prediction Model"
      ],
      "metadata": {
        "id": "RAJXtzAz7hYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.1 Training the Logistic Regression model on the Training set"
      ],
      "metadata": {
        "id": "ida8G8UL7q8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6p3YE-2M7p-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.2 Predicting the Test set results"
      ],
      "metadata": {
        "id": "1tWYDf9L71Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "FSZ1cgWc77TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.3 Making the Confusion Matrix and calculating accuracy"
      ],
      "metadata": {
        "id": "tAKlXMiL7_bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "wtlnl6OD8H3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Support Vector Machine Prediction Model"
      ],
      "metadata": {
        "id": "HojkA7Sx8epo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.1 Training the SVM model on the Training set"
      ],
      "metadata": {
        "id": "ZpCZAHru8wWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "5DxbsLkd82Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.2 Predicting the Test set results"
      ],
      "metadata": {
        "id": "KEj2gGRr85Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "WuIME_AJ88xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.3 Making the Confusion Matrix and calculating accuracy"
      ],
      "metadata": {
        "id": "ByzTlYTI8_W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ZIKUtkB_9D3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Artificial Neural Networks"
      ],
      "metadata": {
        "id": "pRUe5Szw9oRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.1 Building the ANN"
      ],
      "metadata": {
        "id": "Jk4aUFrF-iM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.1.1 Initializing the ANN"
      ],
      "metadata": {
        "id": "D9rW7cAF9tuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "oXAxX6dh9x_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.1.2 Adding the input layer and the first hidden layer"
      ],
      "metadata": {
        "id": "UuwYqWZ_93tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))"
      ],
      "metadata": {
        "id": "4JL9Q5-H99fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.1.3 Adding the second hidden layer"
      ],
      "metadata": {
        "id": "b9EcsBJf-QaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "OvLdbM3B-TjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.1.4 Adding the output layer"
      ],
      "metadata": {
        "id": "TE8qqwst-XBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "QOkKcucD-8Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.2 Training the ANN"
      ],
      "metadata": {
        "id": "4bxfLIm9_BrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.2.1 Compiling the ANN"
      ],
      "metadata": {
        "id": "MAT1kFW0_HKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "-ztb07_A_LAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.2.2 Training the ANN on the Training set"
      ],
      "metadata": {
        "id": "ba48d-hl_N40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "metadata": {
        "id": "hAjBE3lP_TMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.3 Making the predictions and evaluating the model"
      ],
      "metadata": {
        "id": "GSgRl07__XYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.3.1 Predicting the Test set results"
      ],
      "metadata": {
        "id": "5wRfqW-7_dPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "aao8___j_7Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.3.2 Making the Confusion Matrix and calculating accuracy"
      ],
      "metadata": {
        "id": "m2T_lQkQAE77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "6WKRi4erALDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}